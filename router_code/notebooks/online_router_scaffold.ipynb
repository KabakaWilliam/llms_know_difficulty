{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60903b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import litellm \n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f2a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(solutions):\n",
    "    texts = [sol[\"score\"] for sol in solutions]\n",
    "    return Counter(texts).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3686e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_sfx = \"Let's think step by step and output the final answer within \\\\boxed{}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ee9724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_MODEL_CONFIGS = {\n",
    "    \"Qwen/Qwen2.5-Math-1.5B-Instruct\": {\n",
    "        \"model_base\": \"http://localhost:8001/v1\",\n",
    "        \"api_key\": \"token-abc123\",\n",
    "        \"default_temperature\": 0.6,\n",
    "        \"default_max_tokens\": 3000,\n",
    "        \"mode_settings\": {\n",
    "            \"MATH\": {\n",
    "                \"prompt_sfx\": prompt_sfx,\n",
    "                \"default_temperature\": 0.6,\n",
    "                \"default_max_tokens\": 3000,\n",
    "            }\n",
    "        },\n",
    "        \"model_costs\": { # Based on Alibaba CLoud Pricing\n",
    "            \"input_per_mill\": 0.10,\n",
    "            \"output_per_mill\": 0.10\n",
    "        }\n",
    "    },\n",
    "    \"Qwen/Qwen2.5-Math-7B-Instruct\": {\n",
    "        \"model_base\": \"http://localhost:8001/v2\",\n",
    "        \"api_key\": \"token-abc123\",\n",
    "        \"default_temperature\": 0.6,\n",
    "        \"default_max_tokens\": 3000,\n",
    "         \"mode_settings\": {\n",
    "            \"MATH\": {\n",
    "                \"prompt_sfx\": prompt_sfx,\n",
    "                \"default_temperature\": 0.6,\n",
    "                \"default_max_tokens\": 3000,\n",
    "            }\n",
    "        },\n",
    "        \"model_costs\": {\n",
    "            \"input_per_mill\": 0.144,\n",
    "            \"output_per_mill\": 0.287\n",
    "        }\n",
    "    },\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\": {\n",
    "        \"model_base\": \"http://localhost:8001/v3\",\n",
    "        \"api_key\": \"token-abc123\",\n",
    "        \"default_temperature\": 0.6,\n",
    "        \"default_max_tokens\": 32768,\n",
    "         \"mode_settings\": {\n",
    "            \"MATH\": {\n",
    "                \"prompt_sfx\": prompt_sfx,\n",
    "                \"default_temperature\": 0.6,\n",
    "                \"default_max_tokens\": 3000,\n",
    "            }\n",
    "        },\n",
    "        \"model_costs\": {\n",
    "            \"input_per_mill\": 0.574,\n",
    "            \"output_per_mill\": 1.721\n",
    "        }\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bce7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, chosen_model, mode=\"default\"):\n",
    "    VLLM_CONFIG = AVAILABLE_MODEL_CONFIGS[chosen_model]\n",
    "    client = OpenAI(\n",
    "    api_key=VLLM_CONFIG[\"api_key\"],\n",
    "    base_url=VLLM_CONFIG[\"model_base\"],\n",
    "    )\n",
    "\n",
    "    if mode == \"MATH\":\n",
    "        completion = client.completions.create(\n",
    "            model=chosen_model,\n",
    "            prompt=prompt + VLLM_CONFIG[\"mode_settings\"][\"MATH\"][\"prompt_sfx\"],\n",
    "            temperature=VLLM_CONFIG[\"mode_settings\"][\"MATH\"][\"default_temperature\"],\n",
    "            max_tokens=VLLM_CONFIG[\"mode_settings\"][\"MATH\"][\"default_max_tokens\"]\n",
    "        )\n",
    "    else:\n",
    "        completion = client.completions.create(\n",
    "            model=chosen_model,\n",
    "            prompt=prompt,\n",
    "            temperature=VLLM_CONFIG[\"default_temperature\"],\n",
    "            max_tokens=VLLM_CONFIG[\"default_max_tokens\"]\n",
    "        )\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b19994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To solve the problem \\(60 + 7\\), we can break it down into simpler steps:\n",
      "\n",
      "1. Start with the number 60.\n",
      "2. Add the number 7 to 60.\n",
      "\n",
      "When we add 7 to 60, we get:\n",
      "\n",
      "\\[60 + 7 = 67\\]\n",
      "\n",
      "So, the final answer is \\(\\boxed{67}\\).\n"
     ]
    }
   ],
   "source": [
    "completion = get_completion(\"What is 60 + 7?\", chosen_model=\"Qwen/Qwen2.5-Math-1.5B-Instruct\", mode=\"MATH\")\n",
    "print(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "614b0115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-b52e9c3b0d70439d863de228f62f63d9', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text=' To solve the problem \\\\(60 + 7\\\\), we can break it down into simpler steps:\\n\\n1. Start with the number 60.\\n2. Add the number 7 to 60.\\n\\nWhen we add 7 to 60, we get:\\n\\n\\\\[60 + 7 = 67\\\\]\\n\\nSo, the final answer is \\\\(\\\\boxed{67}\\\\).', stop_reason=None, prompt_logprobs=None)], created=1766591073, model='Qwen/Qwen2.5-Math-1.5B-Instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=83, prompt_tokens=24, total_tokens=107, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, kv_transfer_params=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f021fd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 24)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.usage.completion_tokens,completion.usage.prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5099c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_calibrate(p, T):\n",
    "    logit = np.log(p / (1 - p))\n",
    "    return 1 / (1 + np.exp(-logit / T))\n",
    "\n",
    "\n",
    "def best_of_k(p, K, alpha=0.6):\n",
    "    return 1 - (1 - p)**(alpha * K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f76f60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cost(\n",
    "    model_name: str,\n",
    "    prompt_tokens: int,\n",
    "    output_tokens: int,\n",
    "    K: int,\n",
    "):\n",
    "    cfg = AVAILABLE_MODEL_CONFIGS[model_name][\"model_costs\"]\n",
    "\n",
    "    input_cost = (prompt_tokens / 1_000_000) * cfg[\"input_per_mill\"]\n",
    "    output_cost = (output_tokens / 1_000_000) * cfg[\"output_per_mill\"]\n",
    "\n",
    "    return input_cost + K * output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a06ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SUCCESS = 0.8\n",
    "TEMP_T = 1.5\n",
    "ALPHA = 0.6\n",
    "EXPECTED_PROMPT_TOKENS = 800      # MATH problems + CoT\n",
    "EXPECTED_OUTPUT_TOKENS = 1200     # typical math reasoning\n",
    "\n",
    "\n",
    "ROUTING_ACTIONS = [\n",
    "    (\"Qwen/Qwen2.5-Math-1.5B-Instruct\", 1),\n",
    "    (\"Qwen/Qwen2.5-Math-1.5B-Instruct\", 5),\n",
    "    (\"Qwen/Qwen2.5-Math-7B-Instruct\", 1),\n",
    "    (\"Qwen/Qwen2.5-Math-7B-Instruct\", 5),\n",
    "    (\"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\", 1),\n",
    "]\n",
    "\n",
    "def route_question_with_pricing(\n",
    "    probe_score: float,\n",
    "    prompt_tokens: int = EXPECTED_PROMPT_TOKENS,\n",
    "    output_tokens: int = EXPECTED_OUTPUT_TOKENS,\n",
    "):\n",
    "    # 1. calibrate probe output\n",
    "    p = temperature_calibrate(probe_score, TEMP_T)\n",
    "\n",
    "    best = None\n",
    "\n",
    "    for model, K in ROUTING_ACTIONS:\n",
    "        # predicted success\n",
    "        p_kn = best_of_k(p, K, ALPHA)\n",
    "\n",
    "        if p_kn < TARGET_SUCCESS:\n",
    "            continue\n",
    "\n",
    "        cost = estimate_cost(\n",
    "            model_name=model,\n",
    "            prompt_tokens=prompt_tokens,\n",
    "            output_tokens=output_tokens,\n",
    "            K=K,\n",
    "        )\n",
    "\n",
    "        if best is None or cost < best[\"cost\"]:\n",
    "            best = {\n",
    "                \"model\": model,\n",
    "                \"K\": K,\n",
    "                \"pred_success\": p_kn,\n",
    "                \"cost\": cost,\n",
    "            }\n",
    "\n",
    "    # fallback: strongest model, K=1\n",
    "    if best is None:\n",
    "        best = {\n",
    "            \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\",\n",
    "            \"K\": 1,\n",
    "            \"pred_success\": best_of_k(p, 1, ALPHA),\n",
    "            \"cost\": estimate_cost(\n",
    "                \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\",\n",
    "                prompt_tokens,\n",
    "                output_tokens,\n",
    "                1,\n",
    "            )\n",
    "        }\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928833df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_routing(prompt, probe_score):\n",
    "    prompt_len = prompt\n",
    "    route = route_question_with_pricing(probe_score, prompt_len)\n",
    "\n",
    "    solutions = []\n",
    "    for _ in range(route[\"K\"]):\n",
    "        completion = get_completion(\n",
    "            prompt,\n",
    "            chosen_model=route[\"model\"],\n",
    "            mode=\"MATH\"\n",
    "        )\n",
    "        solutions.append({\n",
    "            \"text\": completion.choices[0].text,\n",
    "        })\n",
    "\n",
    "    # For math, verifier > majority vote\n",
    "    return solutions\n",
    "\n",
    "\n",
    "# Log per question\n",
    "# {\n",
    "#   \"probe_score\": 0.23,\n",
    "#   \"chosen_model\": \"Qwen/Qwen2.5-Math-7B-Instruct\",\n",
    "#   \"K\": 1,\n",
    "#   \"predicted_success\": 0.81,\n",
    "#   \"actual_success\": true,\n",
    "#   \"estimated_cost_usd\": 0.0027\n",
    "# }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff-direction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
